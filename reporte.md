<style type="text/css" rel="stylesheet">
div {
  max-width: 450px;
  margin: 0 auto;
}
</style>
<div>

## 每周汇报
###### *Author:高金铭 Date:2023.10.7*
***
***
### **2023**.9.28 - 10.10
###### 本周总结
1. 深入了解原版代码，理清数据流向和处理流程。   
原版代码使用最基础的`tf`语法逐步处理学习过程，尝试是否可以通过新版本高度抽象的函数来简化代码。
2. 对之前复现的Unet代码，尝试使用目前深度学习常用的`Jupyter`来实现具体流程。   
在`Jupyter`环境下，测试数据读取、可视化，测试unet代码的可用性。
3. 尝试使用`tf.dataset()`函数加载数据，重写读数据过程。

###### 遇到的问题
1. ~~在`./example`给的数据中，读出的lidar数据似乎不正确。~~   
2. ~~对原版代码中精细的深度学习计算操作看不太懂，不确定转化其使用简易函数的可能性。~~
3. 调试模型时，发现对输入数据形状有要求，需要其宽高在多次除以二操作后保持为偶数，否则在上采样过程中会产生精度问题，报错。
4. 


###### 后续计划
1. 拿到数据集，进行具体调试更改
2. 暂时没有使用`gt_mask`检查深度数据是否有效
3. 暂未对数据加载预处理
4. 暂未添加`tensorboard`监控
5. 
***
### **2023**.10.11 - 10.17
###### 本周总结
1. 根据数据集进行调试
2. 在L1损失函数里加入`gt_mask`验证
3. 在损失函数里加入平滑损失，减弱生成图的横向纹理和色块
4. 调整数据加载量，使其能在`32GB`内存和`11GB`显存环境运行
5. 使用延迟加载数据
6. 解决一些训练时的bug
7. 可视化预测深度图，对雷达稀疏矩阵等可视化
8. 对数据进行剪裁、规约化等预处理

###### 遇到的问题
1. 训练效果达不到原论文的指标
2. ~~在按照原版代码加入平滑损失以后，效果反而更差~~

###### 后续计划
1. 还未加入多重尺度损失验证
2. 加入更多评价指标
3. 对比原版代码，达到原版模型效果
4. 
***
### **2023**.10.18 - 10.25
###### 本周总结
1. 加入`RMSE`、`ARD`、`MAE`监测指标
2. 分类数据训练，之前是训练整个数据集
3. 之前的`TV Loss`存在bug，没有加入输入张量。现在通过将输入和输出连接作为网络最后一层，将输入带入损失函数
4. 修改其他代码以适应新的网络输出
5. 尝试运行理解`pytorch`的`Unet`代码

###### 遇到的问题
1. 几个指标依然不达标
2. 回顾这段时间，代码编写有些操之过急，很多细节地方欠缺考虑

###### 后续计划
1. 详细学习pytorch的Unet代码，根据其来发现和修正自己代码的问题
2. 阅读论文

***
### **2023**.10.26 - 11.01
###### 本周总结
1. 放弃之前使用的TF高级API，使用`tf.GradientTape`记录模型计算过程、计算梯度，使用`tf.keras.metrics.Mean`来记录loss和各项指标的平均值。
2. 使用`tqdm`库来显示训练进度条
3. 暂时弃用`tf.data.Dataset`数据加载工具的使用，使用原来的数据加载和预处理方法，使得训练结果有显著提升。

###### 遇到的问题
1. `dataset`部分代码对图像的加载和预处理对模型训练结果产生影响
2. 预测图像边缘存在类似遮罩的问题

###### 后续计划
1. 尝试修改`dataset`部分代码，使其可以达到原版代码的效果，同时利用到工具的优势，如GPU加速处理，懒加载等
2. 补全更多指标
3. 加入其他损失


***
### **2023**.11.02 - 11.08
###### 本周总结
1. 修改代码整体结构，抽象出几个参数，用于后面大量测试
2. 加入了所有的评价指标
3. 添加了主动垃圾变量回收，手动清空`TF计算图`，防止多次迭代训练时，显存和内存溢出
4. 添加保存结果和参数到CSV，并且以时间命名保存每次模型权重，方便后续调用，格式为`%H_%M_d_%d_%m_%Y`
5. 测试不同`β1`情况下的`Adam`优化器效果
6. 测试不同`epoch`数量和学习率组合的训练效果
7. 加入了`TV-Loss`平滑损失，整体输出图像确实更好看了，横纹、色块大幅度消失，但是评价指标并没有明显提升
8. 深入阅读`Gated2Gated`论文，以及泛读了一些相关文献
9. 

###### 遇到的问题
~~1. 边缘遮挡问题找不出原因，但是都集中在图像上缘。在数据加载过程部分代码中，对图像进行了剪裁，但是剪裁后的图像并没有遮挡，而是在训练过程中出现的~~
2. 大量测试消耗的训练时间很长，在现在已测的情况下，总共运行时间已经30多个小时了。一部分原因是：   
   1. 数据预处理没有在GPU上执行；
   2. 没有开启TF静态计算图功能，这可以把关键的python逻辑操作全部交由tensorflow执行；
   3. 数据是即加载即用，多次单个硬盘IO时间消耗一部分，可以考虑加入类似“数据池”的功能，或是优化使用`tf.data.Dataset`工具
3. 

###### 后续计划
1. 考虑对训练过程进行优化，减少训练时间
2. 尝试接触`Gated2Gated`代码，文章已经理解的差不多了
3. 测试`batch_size`对训练效果的影响，可能会导致显存不足

***
### **2023**.11.09 - 11.14
###### 本周总结
1. 如果将模型输入改为近似原版且不会导致模型报错的尺寸`(416, 960)`，
则生成的图像边缘没有遮挡，疑似是之前研究人员定好的尺寸，
还没有找到具体原因
2. 阅读`Gated2Gated`代码，理解了其网络结构，但是由于其损失函数过多，
还没有理解其损失函数的具体实现
3. 显示图像颜色映射色谱改为jet，这与G2G代码中使用的一致
4. 学习坐标转换相关资料，捡回一些c++的知识
5. 基本完成对坐标转换的代码实现

###### 遇到的问题
1. 不会离线配置c++环境，导致无法编译测试
2. 对vs的很多报错不明缘由
3. 

###### 后续计划
1. 尝试系统学习vs2022下的c++开发以及环境配置
2. 继续详细了解G2G的代码，了解其整体结构
3. 

***
### **2023**.11.15 - 11.21
###### 本周总结
1. 已经完成在本地测试坐标转换函数的可用性
2. 继续理解`G2G`代码
3. 将项目启动参数抽象为python类，方便在jupyter环境下调试。
一是为了加深理解，二是方便后续的改动和测试

###### 遇到的问题
1. 对于具体的网络结构，如`packnet`，比较复杂，对网络理论理解还不够透彻
2. 

###### 后续计划
1. 准备尝试将选通先验图加入到`G2D`的损失函数中
2. 已经准备好`G2G`的数据集，准备跑网络调试
3. 详细阅读`packnet`论文，理解其网络结构


***
### **2023**.11.22 - 11.28
###### 本周总结
1. 尝试将损失先验加入到损失函数
2. 绘制三个选通图掩码对应预测距离的像素数量直方图，发现在较为激进的选通图掩码下，
该直方图仍然存在大量交叉部分，于是尝试利用选通图试图让网络学习到三张选通图距离关系的特征。
3. 本周测试了一种将其加入损失函数的方式，总体逻辑时仿照直方图的处理方式，找到俩俩选通图交叉点距离`s1`和`s2`，
然后对于对应选通图的距离，按照超出交叉点的距离施加权重，差值越大
4. 分为两个方向：
   1. 第一个时将其化为权重值，在`L1`损失里进行加权处理。
   在经过几次测试后，发现该方向对于指标没有太大影响，但是生成图像的效果有所提升。
   2. 第二个时直接将全部偏差值相加，作为新的损失项，加入到原有损失函数中。
   该方向使指标变差，在多次调整权重参数后，依然不佳，考虑弃用。
5. `calculate_cross_depth_histogram`函数用来计算两个选通掩码对应深度数据的直方图交叉点
6. `depth_prior_loss_c`函数，是目前的深度先验损失函数
7. 

###### 遇到的问题
1. 

###### 后续计划
1. 尝试使用其他方式加入选通图先验，如：
   1. 找到当前像素最近的其他选通图对应的像素进行比较
   2. 对所有的选通先验图跑一遍深度像素交叉点算法，看看当前是否存在比较固定的交叉点
   3. 区域比较，在不同选通先验图选择一块小区域的均值进行比较
   4. 
2. 


</div>



